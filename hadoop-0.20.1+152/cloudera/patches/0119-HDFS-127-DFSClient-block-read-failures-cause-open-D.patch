From d9e9589506f8856fcb607cdf0465bad22f48a267 Mon Sep 17 00:00:00 2001
From: Todd Lipcon <todd@cloudera.com>
Date: Mon, 20 Jul 2009 13:07:43 -0700
Subject: [PATCH] HDFS-127: DFSClient block read failures cause open DFSInputStream to become unusable

HADOOP-4681: Also referenced

This as-yet-uncommitted patch is recommended by HBase people.
Applied patch "4681.patch" attached to the JIRA on 2008-11-18.
---
 src/hdfs/org/apache/hadoop/hdfs/DFSClient.java |    2 ++
 1 files changed, 2 insertions(+), 0 deletions(-)

diff --git a/src/hdfs/org/apache/hadoop/hdfs/DFSClient.java b/src/hdfs/org/apache/hadoop/hdfs/DFSClient.java
index 1170697..b091d11 100644
--- a/src/hdfs/org/apache/hadoop/hdfs/DFSClient.java
+++ b/src/hdfs/org/apache/hadoop/hdfs/DFSClient.java
@@ -1610,6 +1610,7 @@ public class DFSClient implements FSConstants, java.io.Closeable {
       // Connect to best DataNode for desired Block, with potential offset
       //
       DatanodeInfo chosenNode = null;
+      failures = 0;
       while (s == null) {
         DNAddrPair retval = chooseDataNode(targetBlock);
         chosenNode = retval.info;
@@ -1810,6 +1811,7 @@ public class DFSClient implements FSConstants, java.io.Closeable {
       Socket dn = null;
       int numAttempts = block.getLocations().length;
       IOException ioe = null;
+      failures = 0;
       
       while (dn == null && numAttempts-- > 0 ) {
         DNAddrPair retval = chooseDataNode(block);
-- 
1.6.0.4

